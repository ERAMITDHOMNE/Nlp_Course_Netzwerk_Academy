{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "1. Counting Text.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbKXvvUhhMn4",
        "colab_type": "text"
      },
      "source": [
        "# NLTK and the Basics - Counting Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpLnasOChMoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "outputId": "800635a1-980b-4b56-e30c-b9e7476819c9"
      },
      "source": [
        "\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download()\n",
        "nltk.download('punkt')\n",
        "nltk.download('gutenberg')  # Project/module // gutenberg = consist of collection of text files\n",
        "#nltk.corpus()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "Hit Enter to continue: q\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> q\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0JVeJT3hMrN",
        "colab_type": "text"
      },
      "source": [
        "NLTK comes with pre-packed text data. \n",
        "\n",
        "Project Gutenberg is a group that digitizes books and literature that are mostly in the pubic domain.  These works make great examples for practicing NLP.  If you interested in Project Gutenberg, I recommend checking out their site. http://www.gutenberg.org/wiki/Main_Page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18LCFk78hMrm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "2bb53edd-71bd-4011-93ae-1c6bb1a3c4ce"
      },
      "source": [
        "nltk.corpus.gutenberg.fileids()   #  , nltk = tools -> corpus =corpus = collection of document -> gutenberg -. project (collection of files) -> files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG3QJaFnhMte",
        "colab_type": "text"
      },
      "source": [
        "You will notice that every file name has the letter \"u\" before it. The 'u' is part of the external representation of the file name, meaning it's a Unicode string as opposed to a byte string. It is not part of the string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ29dU_8hMt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "md = nltk.corpus.gutenberg.words(\"chesterton-thursday.txt\")  # md = variable ,Ascii , binary  ,u = unicode \\u , A - 1 , b_ 0, 0000000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZt035tle6F2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e845c6ce-2774-4df1-bc28-8909910fbf88"
      },
      "source": [
        "print(md)   # content of my file ,, # .....  = lot of words are there so it is showing only few"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[', 'The', 'Man', 'Who', 'Was', 'Thursday', 'by', ...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAgwS_lIhMvY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "231ef54a-922b-444b-aae9-27f5ec390f3a"
      },
      "source": [
        "md[0:100]  # index 0 to 99 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[',\n",
              " 'The',\n",
              " 'Man',\n",
              " 'Who',\n",
              " 'Was',\n",
              " 'Thursday',\n",
              " 'by',\n",
              " 'G',\n",
              " '.',\n",
              " 'K',\n",
              " '.',\n",
              " 'Chesterton',\n",
              " '1908',\n",
              " ']',\n",
              " 'To',\n",
              " 'Edmund',\n",
              " 'Clerihew',\n",
              " 'Bentley',\n",
              " 'A',\n",
              " 'cloud',\n",
              " 'was',\n",
              " 'on',\n",
              " 'the',\n",
              " 'mind',\n",
              " 'of',\n",
              " 'men',\n",
              " ',',\n",
              " 'and',\n",
              " 'wailing',\n",
              " 'went',\n",
              " 'the',\n",
              " 'weather',\n",
              " ',',\n",
              " 'Yea',\n",
              " ',',\n",
              " 'a',\n",
              " 'sick',\n",
              " 'cloud',\n",
              " 'upon',\n",
              " 'the',\n",
              " 'soul',\n",
              " 'when',\n",
              " 'we',\n",
              " 'were',\n",
              " 'boys',\n",
              " 'together',\n",
              " '.',\n",
              " 'Science',\n",
              " 'announced',\n",
              " 'nonentity',\n",
              " 'and',\n",
              " 'art',\n",
              " 'admired',\n",
              " 'decay',\n",
              " ';',\n",
              " 'The',\n",
              " 'world',\n",
              " 'was',\n",
              " 'old',\n",
              " 'and',\n",
              " 'ended',\n",
              " ':',\n",
              " 'but',\n",
              " 'you',\n",
              " 'and',\n",
              " 'I',\n",
              " 'were',\n",
              " 'gay',\n",
              " ';',\n",
              " 'Round',\n",
              " 'us',\n",
              " 'in',\n",
              " 'antic',\n",
              " 'order',\n",
              " 'their',\n",
              " 'crippled',\n",
              " 'vices',\n",
              " 'came',\n",
              " '--',\n",
              " 'Lust',\n",
              " 'that',\n",
              " 'had',\n",
              " 'lost',\n",
              " 'its',\n",
              " 'laughter',\n",
              " ',',\n",
              " 'fear',\n",
              " 'that',\n",
              " 'had',\n",
              " 'lost',\n",
              " 'its',\n",
              " 'shame',\n",
              " '.',\n",
              " 'Like',\n",
              " 'the',\n",
              " 'white',\n",
              " 'lock',\n",
              " 'of',\n",
              " 'Whistler',\n",
              " ',']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzajKfDXhMw7",
        "colab_type": "text"
      },
      "source": [
        "We can count how many times a word appears in the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSUDVxxKhMxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "17196933-0ba4-4cd9-af2b-b5fcdda93d54"
      },
      "source": [
        "md.count(\"boys\")  # counting the word in file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz6hZ7JnhMyp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3797b0ff-c26d-4a63-dcb8-36d5646e60a8"
      },
      "source": [
        "md.count(\"boat\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJCuyR0EhMz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "31580562-d1a2-4017-f650-c8e5a4cab1ff"
      },
      "source": [
        "md.count(\"Science\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-k0qN5jhM1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ee12eca8-a630-4b63-ce04-bc43e04bf590"
      },
      "source": [
        "md.count(\"laptop\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmDS6mXJhM2V",
        "colab_type": "text"
      },
      "source": [
        "We can get an idea of how long the book is by seeing how many items are in our list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg5o5b93hM2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4b1517ad-b4b2-40eb-ee25-9cdcaef07c3c"
      },
      "source": [
        "len(md)  # count the number of words in file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14hlxJGyhM3v",
        "colab_type": "text"
      },
      "source": [
        "We can see how many unique words are used in the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGxTIdpghM3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "md_set = set(md) # finding unique words inset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATCzgv29hM5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "99ed4acd-c3c1-4a1b-a4be-b805d5f90042"
      },
      "source": [
        "len(md_set)  # count unique words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1myKEhmmhM6Q",
        "colab_type": "text"
      },
      "source": [
        "We can calculate the average number of times any given word is used in the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vF9YPPWhM6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division #we import this since we are using Python 2.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbRpeipUhM7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2cebcc44-5548-4682-8581-ea5e2cb6543b"
      },
      "source": [
        "len(md)/len(md_set)   # specific words average appearing 10 time in my file , cal "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.167915381225209"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa5Kvn61hM8j",
        "colab_type": "text"
      },
      "source": [
        "We can look at the book as a lists of sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfmxxKjdhM8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "md_sents = nltk.corpus.gutenberg.sents(\"melville-moby_dick.txt\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aec5h9I3hM9u",
        "colab_type": "text"
      },
      "source": [
        "We can calculate the average number of words per sentence in the book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPZuZbBdhM94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2b21e1e1-2316-4e8b-db84-becd8135fb8e"
      },
      "source": [
        "len(md)/len(md_sents)  , md_sents = collection of unique sentences  , t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.880703847300924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}