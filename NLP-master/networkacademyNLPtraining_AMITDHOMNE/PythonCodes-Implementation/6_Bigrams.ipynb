{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "6. Bigrams.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18U2h7olp35j",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# NLTK and the Basics - Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgCp62Aop36K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "662d7aa8-488a-42c2-974e-c12e24ca7866"
      },
      "source": [
        "\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download()\n",
        "nltk.download('punkt')  # depend text file and your program \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59VbhS0Rp38x",
        "colab_type": "text"
      },
      "source": [
        "Bigrams, sometimes called 2grams, or ngrams (when dealing with a different number), is a way of looking at word sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9PBZxZLp39E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \" I think it might rain today and tomorrow will be sunny.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VgoyQVjp3-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = nltk.word_tokenize(text) # tokenization means like : I, think ,it ,might,rain,today..... , pow in math.h , # include<math.h>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC7PdIvmp3_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "cfc60616-3106-4e6f-8e42-958f6d02d941"
      },
      "source": [
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'think',\n",
              " 'it',\n",
              " 'might',\n",
              " 'rain',\n",
              " 'today',\n",
              " 'and',\n",
              " 'tomorrow',\n",
              " 'will',\n",
              " 'be',\n",
              " 'sunny',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybA6QTdbp4A2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigrams =  nltk.bigrams(tokens)  # n = 2  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXXU64Rep4CB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "1d313124-4311-4967-d3fb-44d6904d8897"
      },
      "source": [
        "for item in bigrams:  # item is temporary variable\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('I', 'think')\n",
            "('think', 'it')\n",
            "('it', 'might')\n",
            "('might', 'rain')\n",
            "('rain', 'today')\n",
            "('today', 'and')\n",
            "('and', 'tomorrow')\n",
            "('tomorrow', 'will')\n",
            "('will', 'be')\n",
            "('be', 'sunny')\n",
            "('sunny', '.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c7am_6Vp4DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trigrams = nltk.trigrams(tokens) # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KBC0VKHp4EN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0df9a5aa-dce1-427a-df76-b178f751f5a6"
      },
      "source": [
        "for item in trigrams:  # for giving more weight , sentence = a b c  [a - 0.90  , b  = 0.40 , c =0.03 ]\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('I', 'think', 'it')\n",
            "('think', 'it', 'might')\n",
            "('it', 'might', 'rain')\n",
            "('might', 'rain', 'today')\n",
            "('rain', 'today', 'and')\n",
            "('today', 'and', 'tomorrow')\n",
            "('and', 'tomorrow', 'will')\n",
            "('tomorrow', 'will', 'be')\n",
            "('will', 'be', 'sunny')\n",
            "('be', 'sunny', '.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI2vciyep4FN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.util import ngrams    # n 4, 5,6....., It depend on programmer ,value of N,you need to change value of N,to improve accuracy,just trial and run and check"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muDo0np2p4GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"If it is nice out, I will go to the beach and have a bath.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2zjtoWFp4HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = nltk.word_tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF7WP04tp4IA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigrams = ngrams(tokens,6)  n= 6 n-1=5 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvxonSh0p4Iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "77e01d95-1718-46c5-d545-10a4a6e210cb"
      },
      "source": [
        "for item in bigrams:   # n-1 value added to next line for memory and to learn context and precise vector representation of feature/text\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('If', 'it', 'is', 'nice', 'out', ',')\n",
            "('it', 'is', 'nice', 'out', ',', 'I')\n",
            "('is', 'nice', 'out', ',', 'I', 'will')\n",
            "('nice', 'out', ',', 'I', 'will', 'go')\n",
            "('out', ',', 'I', 'will', 'go', 'to')\n",
            "(',', 'I', 'will', 'go', 'to', 'the')\n",
            "('I', 'will', 'go', 'to', 'the', 'beach')\n",
            "('will', 'go', 'to', 'the', 'beach', 'and')\n",
            "('go', 'to', 'the', 'beach', 'and', 'have')\n",
            "('to', 'the', 'beach', 'and', 'have', 'a')\n",
            "('the', 'beach', 'and', 'have', 'a', 'bath')\n",
            "('beach', 'and', 'have', 'a', 'bath', '.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3mbePK0p4Jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fourgrams = ngrams(tokens,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89XwM3VIp4KG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e08b9f89-1ee1-4f5d-d586-0fef945335bd"
      },
      "source": [
        "for item in fourgrams:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('If', 'it', 'is', 'nice')\n",
            "('it', 'is', 'nice', 'out')\n",
            "('is', 'nice', 'out', ',')\n",
            "('nice', 'out', ',', 'I')\n",
            "('out', ',', 'I', 'will')\n",
            "(',', 'I', 'will', 'go')\n",
            "('I', 'will', 'go', 'to')\n",
            "('will', 'go', 'to', 'the')\n",
            "('go', 'to', 'the', 'beach')\n",
            "('to', 'the', 'beach', 'and')\n",
            "('the', 'beach', 'and', 'have')\n",
            "('beach', 'and', 'have', 'a')\n",
            "('and', 'have', 'a', 'bath')\n",
            "('have', 'a', 'bath', '.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etfsf_P6p4Kv",
        "colab_type": "text"
      },
      "source": [
        "We can build a function to find any ngram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC1N8un3p4K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def n_grams(text,n):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    grams = ngrams(tokens,n)\n",
        "    return grams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xelkdBBRp4Lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"I think it might rain today, but if it is nice out, I will go to the beach.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsis1k7Yp4L_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grams = n_grams(text, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH_lOcjSp4Ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "7ebbae39-e6c7-4cb2-cdbc-c4e1efccacae"
      },
      "source": [
        "for item in grams:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('I', 'think', 'it', 'might', 'rain')\n",
            "('think', 'it', 'might', 'rain', 'today')\n",
            "('it', 'might', 'rain', 'today', ',')\n",
            "('might', 'rain', 'today', ',', 'but')\n",
            "('rain', 'today', ',', 'but', 'if')\n",
            "('today', ',', 'but', 'if', 'it')\n",
            "(',', 'but', 'if', 'it', 'is')\n",
            "('but', 'if', 'it', 'is', 'nice')\n",
            "('if', 'it', 'is', 'nice', 'out')\n",
            "('it', 'is', 'nice', 'out', ',')\n",
            "('is', 'nice', 'out', ',', 'I')\n",
            "('nice', 'out', ',', 'I', 'will')\n",
            "('out', ',', 'I', 'will', 'go')\n",
            "(',', 'I', 'will', 'go', 'to')\n",
            "('I', 'will', 'go', 'to', 'the')\n",
            "('will', 'go', 'to', 'the', 'beach')\n",
            "('go', 'to', 'the', 'beach', '.')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}